{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221317c0",
   "metadata": {},
   "source": [
    "# Pricing Data Analyst Intern Task: Solutions Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e76129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d82011",
   "metadata": {},
   "source": [
    "## First of all we need to extract our data sets into separate csv files ↓↓↓ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93baf26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Sales_orders.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     18\u001b[0m     input_excel_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 19\u001b[0m     extract_sheets_to_csv(input_excel_file)\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36mextract_sheets_to_csv\u001b[1;34m(input_file)\u001b[0m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(xls, sheet_name)\n\u001b[0;32m     13\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Sales_orders.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating a func that extracts the last 3 sheets from an Excel file and saves each sheet as a separate CSV file.\n",
    "#data excel fiel should be existing in the current directory\n",
    "\n",
    "def extract_sheets_to_csv(input_file):\n",
    "    # Read the Excel file\n",
    "    xls = pd.ExcelFile(input_file)\n",
    "\n",
    "    # Get the sheet names (last 3 sheets in our case contains the data we need)\n",
    "    sheet_names = xls.sheet_names[-3:]\n",
    "\n",
    "    # Extract each sheet to a separate CSV file, and print it's name to make sure it is extracted\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name)\n",
    "        output_file = f\"{sheet_name}.csv\"\n",
    "        df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"Saved {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_excel_file = \"Data.xlsx\"  \n",
    "    extract_sheets_to_csv(input_excel_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5344af8",
   "metadata": {},
   "source": [
    "## Now we'll Load our datasets into Pandas Dataframes ↓↓↓ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96747844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Paths to the CSV files (Make sure they are in the same directory as the notebook)\n",
    "sales_orders_path = 'Sales_orders.csv'\n",
    "cost_of_goods_path = 'Cost_of_Goods.csv'\n",
    "product_sales_orders_path = 'Product_sales_order.csv'\n",
    "\n",
    "\n",
    "# Load the CSV files with UTF-8 encoding and handle thousand separators\n",
    "sales_orders = pd.read_csv(sales_orders_path, encoding='utf-8', thousands=',')\n",
    "cost_of_goods = pd.read_csv(cost_of_goods_path, encoding='utf-8')\n",
    "product_sales_orders = pd.read_csv(product_sales_orders_path, encoding='utf-8', thousands=',')\n",
    "\n",
    "\n",
    "# Set data types for sales_orders\n",
    "sales_orders['ORDER_ID'] = sales_orders['ORDER_ID'].astype(int)\n",
    "# sales_orders['DATE'] = pd.to_datetime(sales_orders['DATE'], format='%B %d, %Y')\n",
    "sales_orders['DATE'] = pd.to_datetime(sales_orders['DATE'], format='%Y-%m-%d')\n",
    "sales_orders['DAY_NAME'] = sales_orders['DAY_NAME'].astype(str)\n",
    "sales_orders['Order_status'] = sales_orders['Order_status'].astype(str)\n",
    "sales_orders['SALES'] = sales_orders['SALES'].astype(float)\n",
    "\n",
    "\n",
    "# Set data types for cost_of_goods\n",
    "cost_of_goods['PRODUCT_ID'] = cost_of_goods['product_id'].astype(int)\n",
    "cost_of_goods['purchase_price'] = cost_of_goods['purchase_price'].astype(float)\n",
    "cost_of_goods['selling_price'] = cost_of_goods['selling_price'].astype(float)\n",
    "\n",
    "\n",
    "# Set data types for product_sales_orders\n",
    "product_sales_orders['PRODUCT_SALES_ORDER_ID'] = product_sales_orders['PRODUCT_SALES_ORDER_ID'].astype(int)\n",
    "product_sales_orders['SALES_ORDER_ID'] = product_sales_orders['SALES_ORDER_ID'].astype(int)\n",
    "product_sales_orders['PRODUCT_ID'] = product_sales_orders['PRODUCT_ID'].astype(int)\n",
    "product_sales_orders['SALES'] = product_sales_orders['SALES'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00275ef",
   "metadata": {},
   "source": [
    "## Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a9a6f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17163 entries, 0 to 17162\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   ORDER_ID      17163 non-null  int32         \n",
      " 1   DATE          17163 non-null  datetime64[ns]\n",
      " 2   DAY_NAME      17163 non-null  object        \n",
      " 3   Order_status  17163 non-null  object        \n",
      " 4   SALES         17162 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), object(2)\n",
      "memory usage: 603.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      26 non-null     int64  \n",
      " 1   purchase_price  26 non-null     float64\n",
      " 2   selling_price   26 non-null     float64\n",
      " 3   PRODUCT_ID      26 non-null     int32  \n",
      "dtypes: float64(2), int32(1), int64(1)\n",
      "memory usage: 860.0 bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20278 entries, 0 to 20277\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PRODUCT_SALES_ORDER_ID  20278 non-null  int32  \n",
      " 1   SALES_ORDER_ID          20278 non-null  int32  \n",
      " 2   PRODUCT_ID              20278 non-null  int32  \n",
      " 3   SALES                   20278 non-null  float64\n",
      "dtypes: float64(1), int32(3)\n",
      "memory usage: 396.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Verify the data types\n",
    "print(sales_orders.info())\n",
    "print(cost_of_goods.info())\n",
    "print(product_sales_orders.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7851db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ORDER_ID       DATE DAY_NAME Order_status    SALES\n",
      "0   6387833 2023-10-01      Sun    Delivered   285.50\n",
      "1   6385549 2023-10-01      Sun    Delivered  1512.25\n",
      "2   6387475 2023-10-01      Sun    Delivered   197.50\n",
      "3   6389331 2023-10-01      Sun    Delivered    67.50\n",
      "4   6390122 2023-10-01      Sun    Delivered   118.00\n",
      "   product_id  purchase_price  selling_price  PRODUCT_ID\n",
      "0         415          270.56         281.75         415\n",
      "1        3495           20.01          21.75        3495\n",
      "2         152          205.08         212.25         152\n",
      "3          72          508.79         540.75          72\n",
      "4         974          134.01         144.25         974\n",
      "   PRODUCT_SALES_ORDER_ID  SALES_ORDER_ID  PRODUCT_ID   SALES\n",
      "0                68097611         6460123        2438  390.00\n",
      "1                68009163         6448262        1087  122.25\n",
      "2                68097089         6460054         142  166.32\n",
      "3                68060918         6455556         415  226.50\n",
      "4                68144928         6466586         361  336.00\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to verify the content\n",
    "print(sales_orders.head())\n",
    "print(cost_of_goods.head())\n",
    "print(product_sales_orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acab3d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ORDER_ID                           DATE         SALES\n",
      "count  1.716300e+04                          17163  1.716200e+04\n",
      "mean   6.444773e+06  2023-10-10 09:19:32.312532736 -1.858798e+02\n",
      "min    6.383207e+06            2023-10-01 00:00:00 -1.000000e+07\n",
      "25%    6.414099e+06            2023-10-05 00:00:00  1.590000e+02\n",
      "50%    6.442612e+06            2023-10-10 00:00:00  2.355000e+02\n",
      "75%    6.475502e+06            2023-10-16 00:00:00  4.260000e+02\n",
      "max    6.524009e+06            2023-10-21 00:00:00  9.568750e+03\n",
      "std    3.585509e+04                            NaN  7.633851e+04\n",
      "        product_id  purchase_price  selling_price   PRODUCT_ID\n",
      "count    26.000000    2.600000e+01      26.000000    26.000000\n",
      "mean   3277.230769    3.846339e+06     213.980769  3277.230769\n",
      "std    3441.946209    1.961158e+07     142.814161  3441.946209\n",
      "min      72.000000   -2.000000e+02      21.750000    72.000000\n",
      "25%     458.500000    1.206600e+02     130.375000   458.500000\n",
      "50%    1493.500000    1.823300e+02     189.750000  1493.500000\n",
      "75%    6189.000000    2.699400e+02     281.000000  6189.000000\n",
      "max    9468.000000    1.000000e+08     557.750000  9468.000000\n",
      "       PRODUCT_SALES_ORDER_ID  SALES_ORDER_ID    PRODUCT_ID         SALES\n",
      "count            2.027800e+04    2.027800e+04  20278.000000  20278.000000\n",
      "mean             6.799118e+07    6.444869e+06   3040.886182    336.038018\n",
      "std              2.539093e+05    3.589145e+04   3357.193506    477.818932\n",
      "min              6.755815e+07    6.383207e+06     72.000000     16.000000\n",
      "25%              6.777472e+07    6.414147e+06    417.000000    155.000000\n",
      "50%              6.797202e+07    6.442638e+06   1087.000000    213.750000\n",
      "75%              6.821038e+07    6.475657e+06   3900.000000    372.500000\n",
      "max              6.854537e+07    6.524009e+06   9468.000000   9568.750000\n"
     ]
    }
   ],
   "source": [
    "print(sales_orders.describe())\n",
    "print(cost_of_goods.describe())\n",
    "print(product_sales_orders.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7330db",
   "metadata": {},
   "source": [
    "## Data Cleaning Process ↓↓↓:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6ca3c",
   "metadata": {},
   "source": [
    "### 1. Cleaning Dataset1 (Sales_orders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f4ec2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['SALES']  \n",
      " ,Sum of missing values: \n",
      " ORDER_ID        0\n",
      "DATE            0\n",
      "DAY_NAME        0\n",
      "Order_status    0\n",
      "SALES           1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identify columns with missing values (NaN or null).\n",
    "missing_values_columns = sales_orders.isna().any()\n",
    "sum_missing_values_columns= sales_orders.isna().sum()\n",
    "columns_with_missing_values = missing_values_columns[missing_values_columns].index.tolist()\n",
    "print(\"Columns with missing values:\", columns_with_missing_values, \" \\n ,Sum of missing values: \\n\",sum_missing_values_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "165b891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER_IDs of records with null value in SALES column: [6383668]\n"
     ]
    }
   ],
   "source": [
    "# Check the ORDER_ID of the Missing SALES value\n",
    "null_sales_order_ids = sales_orders[sales_orders['SALES'].isna()]['ORDER_ID']\n",
    "\n",
    "print(\"ORDER_IDs of records with null value in SALES column:\", null_sales_order_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11dc5838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row for SALES_ORDER_ID 6383668:\n",
      "        PRODUCT_SALES_ORDER_ID  SALES_ORDER_ID  PRODUCT_ID  SALES\n",
      "10282                67561235         6383668        1070  392.5\n",
      "15218                67561236         6383668         152  334.0\n"
     ]
    }
   ],
   "source": [
    "# Checking if this point of sale is existing in the product_sales_orders df, using the ORDER_ID [6383668]\n",
    "#looking for is 6383668 in product_sales_orders\n",
    "order_id_to_find = 6383668\n",
    "# Use 'SALES_ORDER_ID' instead of 'ORDER_ID' for filtering\n",
    "filtered_df = product_sales_orders[product_sales_orders['SALES_ORDER_ID'] == order_id_to_find]\n",
    "\n",
    "# Check if the resulting DataFrame is empty\n",
    "if filtered_df.empty:\n",
    "    print(f\"No records found for SALES_ORDER_ID {order_id_to_find}.\")\n",
    "else:\n",
    "    print(\"Row for SALES_ORDER_ID 6383668:\\n\", filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efe597df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ORDER_ID       DATE DAY_NAME Order_status  SALES\n",
      "29   6383668 2023-10-01      Sun    Delivered  726.5\n"
     ]
    }
   ],
   "source": [
    "# it turns out that the order 6383668 involves the sale of more than one product,\n",
    "#so the Total revenue per this order is the sum of the Total revenue per order per these two products\n",
    "# this means that we're going to fill the missing value of SALES in Sales_orders with 392.5+334.0\n",
    "\n",
    "# Step 1: Calculate the sum of SALES for the specific SALES_ORDER_ID\n",
    "sales_sum = filtered_df['SALES'].sum()\n",
    "\n",
    "# Step 2: Locate the row in sales_orders with the matching SALES_ORDER_ID\n",
    "sales_orders.loc[sales_orders['ORDER_ID'] == order_id_to_find, 'SALES'] = sales_sum\n",
    "\n",
    "# Display the updated sales_orders DataFrame to verify the change\n",
    "print(sales_orders[sales_orders['ORDER_ID'] == order_id_to_find])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b600c65b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER_IDs of records with null value in SALES column: []\n"
     ]
    }
   ],
   "source": [
    "#Double Check the ORDER_ID of the Missing SALES value\n",
    "null_sales_order_ids = sales_orders[sales_orders['SALES'].isna()]['ORDER_ID']\n",
    "\n",
    "print(\"ORDER_IDs of records with null value in SALES column:\", null_sales_order_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a8a8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in SALES: -10000000.0\n",
      "Maximum value in SALES: 9568.75\n"
     ]
    }
   ],
   "source": [
    "# CHecking for outliers in SALES col of sales_orders\n",
    "column_name = 'SALES'\n",
    "\n",
    "min_val = sales_orders[column_name].min()\n",
    "max_val = sales_orders[column_name].max()\n",
    "\n",
    "print(f\"Minimum value in {column_name}: {min_val}\")\n",
    "print(f\"Maximum value in {column_name}: {max_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "987f64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The order(s) that lost the company 10 million is/are: [6418568]\n"
     ]
    }
   ],
   "source": [
    "# there is a record in SALES that indicate a minus 10 million of revenue per this order\n",
    "#let's check this order id\n",
    "# Locate the order with the minimum sales value and extract the order ID(s) as a list\n",
    "tenmillion_loss_order_ids = sales_orders.loc[sales_orders['SALES'] == min_val, 'ORDER_ID'].tolist()\n",
    "\n",
    "print(\"The order(s) that lost the company 10 million is/are:\", tenmillion_loss_order_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69c970bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row for SALES_ORDER_ID 6383668:\n",
      "        PRODUCT_SALES_ORDER_ID  SALES_ORDER_ID  PRODUCT_ID    SALES\n",
      "18757                67805080         6418568        9081  3521.25\n"
     ]
    }
   ],
   "source": [
    "#looking for is 6418568 in product_sales_orders\n",
    "order_id_to_find = 6418568\n",
    "# Use 'SALES_ORDER_ID' instead of 'ORDER_ID' for filtering\n",
    "filtered_df = product_sales_orders[product_sales_orders['SALES_ORDER_ID'] == order_id_to_find]\n",
    "\n",
    "# Check if the resulting DataFrame is empty\n",
    "if filtered_df.empty:\n",
    "    print(f\"No records found for SALES_ORDER_ID {order_id_to_find}.\")\n",
    "else:\n",
    "    print(\"Row for SALES_ORDER_ID 6383668:\\n\", filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f25d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ORDER_ID       DATE DAY_NAME Order_status    SALES\n",
      "4713   6418568 2023-10-06      Fri    Delivered  3521.25\n"
     ]
    }
   ],
   "source": [
    "# It turns out that the loss of ten million was a corrupted record and the revenue of that order was 3521.25\n",
    "# so we'll replace this record with the correct value\n",
    "\n",
    "# Step 1: Calculate the sum of SALES for the specific SALES_ORDER_ID\n",
    "sales_sum = filtered_df['SALES'].sum()\n",
    "\n",
    "# Step 2: Locate the row in sales_orders with the matching SALES_ORDER_ID\n",
    "sales_orders.loc[sales_orders['ORDER_ID'] == order_id_to_find, 'SALES'] = sales_sum\n",
    "\n",
    "# Display the updated sales_orders DataFrame to verify the change\n",
    "print(sales_orders[sales_orders['ORDER_ID'] == order_id_to_find])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c50fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in SALES: 16.0\n",
      "Maximum value in SALES: 9568.75\n"
     ]
    }
   ],
   "source": [
    "# double CHecking for outliers in SALES col of sales_orders\n",
    "column_name = 'SALES'\n",
    "\n",
    "min_val = sales_orders[column_name].min()\n",
    "max_val = sales_orders[column_name].max()\n",
    "\n",
    "print(f\"Minimum value in {column_name}: {min_val}\")\n",
    "print(f\"Maximum value in {column_name}: {max_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316a4a6",
   "metadata": {},
   "source": [
    "## 2. Cleaning Dataset 2 (Cost_of_Goods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8587b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: []  \n",
      " ,Sum of missing values: \n",
      " product_id        0\n",
      "purchase_price    0\n",
      "selling_price     0\n",
      "PRODUCT_ID        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identify columns with missing values (NaN or null).\n",
    "missing_values_columns = cost_of_goods.isna().any()\n",
    "sum_missing_values_columns= cost_of_goods.isna().sum()\n",
    "columns_with_missing_values = missing_values_columns[missing_values_columns].index.tolist()\n",
    "print(\"Columns with missing values:\", columns_with_missing_values, \" \\n ,Sum of missing values: \\n\",sum_missing_values_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d680fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        product_id  purchase_price  selling_price   PRODUCT_ID\n",
      "count    26.000000    2.600000e+01      26.000000    26.000000\n",
      "mean   3277.230769    3.846339e+06     213.980769  3277.230769\n",
      "std    3441.946209    1.961158e+07     142.814161  3441.946209\n",
      "min      72.000000   -2.000000e+02      21.750000    72.000000\n",
      "25%     458.500000    1.206600e+02     130.375000   458.500000\n",
      "50%    1493.500000    1.823300e+02     189.750000  1493.500000\n",
      "75%    6189.000000    2.699400e+02     281.000000  6189.000000\n",
      "max    9468.000000    1.000000e+08     557.750000  9468.000000\n"
     ]
    }
   ],
   "source": [
    "#explore the cost of goods data\n",
    "print(cost_of_goods.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae3f9194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415</td>\n",
       "      <td>2.705600e+02</td>\n",
       "      <td>281.75</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3495</td>\n",
       "      <td>2.001000e+01</td>\n",
       "      <td>21.75</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>2.050800e+02</td>\n",
       "      <td>212.25</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>5.087900e+02</td>\n",
       "      <td>540.75</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>974</td>\n",
       "      <td>1.340100e+02</td>\n",
       "      <td>144.25</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2438</td>\n",
       "      <td>4.089000e+01</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3900</td>\n",
       "      <td>5.019900e+02</td>\n",
       "      <td>557.75</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>361</td>\n",
       "      <td>1.688775e+02</td>\n",
       "      <td>189.75</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3575</td>\n",
       "      <td>2.680800e+02</td>\n",
       "      <td>282.25</td>\n",
       "      <td>3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6952</td>\n",
       "      <td>1.448300e+02</td>\n",
       "      <td>155.50</td>\n",
       "      <td>6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1765</td>\n",
       "      <td>1.571900e+02</td>\n",
       "      <td>163.00</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2778</td>\n",
       "      <td>1.563600e+02</td>\n",
       "      <td>166.50</td>\n",
       "      <td>2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9468</td>\n",
       "      <td>9.206000e+01</td>\n",
       "      <td>96.50</td>\n",
       "      <td>9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1070</td>\n",
       "      <td>4.526000e+01</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9046</td>\n",
       "      <td>2.047800e+02</td>\n",
       "      <td>215.50</td>\n",
       "      <td>9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>168</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>68.50</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>583</td>\n",
       "      <td>2.630500e+02</td>\n",
       "      <td>278.75</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1080</td>\n",
       "      <td>1.430700e+02</td>\n",
       "      <td>153.25</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>142</td>\n",
       "      <td>1.822200e+02</td>\n",
       "      <td>189.75</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7558</td>\n",
       "      <td>3.940200e+02</td>\n",
       "      <td>412.50</td>\n",
       "      <td>7558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1222</td>\n",
       "      <td>3.456700e+02</td>\n",
       "      <td>350.00</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9081</td>\n",
       "      <td>6.721000e+01</td>\n",
       "      <td>72.00</td>\n",
       "      <td>9081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>417</td>\n",
       "      <td>1.824400e+02</td>\n",
       "      <td>189.75</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1087</td>\n",
       "      <td>1.875300e+02</td>\n",
       "      <td>197.50</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9289</td>\n",
       "      <td>3.888000e+02</td>\n",
       "      <td>408.25</td>\n",
       "      <td>9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8120</td>\n",
       "      <td>1.162100e+02</td>\n",
       "      <td>125.75</td>\n",
       "      <td>8120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  purchase_price  selling_price  PRODUCT_ID\n",
       "0          415    2.705600e+02         281.75         415\n",
       "1         3495    2.001000e+01          21.75        3495\n",
       "2          152    2.050800e+02         212.25         152\n",
       "3           72    5.087900e+02         540.75          72\n",
       "4          974    1.340100e+02         144.25         974\n",
       "5         2438    4.089000e+01          43.00        2438\n",
       "6         3900    5.019900e+02         557.75        3900\n",
       "7          361    1.688775e+02         189.75         361\n",
       "8         3575    2.680800e+02         282.25        3575\n",
       "9         6952    1.448300e+02         155.50        6952\n",
       "10        1765    1.571900e+02         163.00        1765\n",
       "11        2778    1.563600e+02         166.50        2778\n",
       "12        9468    9.206000e+01          96.50        9468\n",
       "13        1070    4.526000e+01          47.00        1070\n",
       "14        9046    2.047800e+02         215.50        9046\n",
       "15         168    1.000000e+08          68.50         168\n",
       "16         583    2.630500e+02         278.75         583\n",
       "17        1080    1.430700e+02         153.25        1080\n",
       "18         142    1.822200e+02         189.75         142\n",
       "19        7558    3.940200e+02         412.50        7558\n",
       "20        1222    3.456700e+02         350.00        1222\n",
       "21        9081    6.721000e+01          72.00        9081\n",
       "22         417    1.824400e+02         189.75         417\n",
       "23        1087    1.875300e+02         197.50        1087\n",
       "24        9289    3.888000e+02         408.25        9289\n",
       "25        8120    1.162100e+02         125.75        8120"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify rows with negative purchase_price\n",
    "negative_values = cost_of_goods['purchase_price'] < 0\n",
    "\n",
    "# Calculate the replacement value: selling_price - 11% * selling_price\n",
    "replacement_value = cost_of_goods['selling_price'] - 0.11 * cost_of_goods['selling_price']\n",
    "\n",
    "# Replace negative purchase_price values with the calculated replacement value\n",
    "cost_of_goods.loc[negative_values, 'purchase_price'] = replacement_value[negative_values]\n",
    "cost_of_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce4dc9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415</td>\n",
       "      <td>270.5600</td>\n",
       "      <td>281.75</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3495</td>\n",
       "      <td>20.0100</td>\n",
       "      <td>21.75</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>205.0800</td>\n",
       "      <td>212.25</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>508.7900</td>\n",
       "      <td>540.75</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>974</td>\n",
       "      <td>134.0100</td>\n",
       "      <td>144.25</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2438</td>\n",
       "      <td>40.8900</td>\n",
       "      <td>43.00</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3900</td>\n",
       "      <td>501.9900</td>\n",
       "      <td>557.75</td>\n",
       "      <td>3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>361</td>\n",
       "      <td>168.8775</td>\n",
       "      <td>189.75</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3575</td>\n",
       "      <td>268.0800</td>\n",
       "      <td>282.25</td>\n",
       "      <td>3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6952</td>\n",
       "      <td>144.8300</td>\n",
       "      <td>155.50</td>\n",
       "      <td>6952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1765</td>\n",
       "      <td>157.1900</td>\n",
       "      <td>163.00</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2778</td>\n",
       "      <td>156.3600</td>\n",
       "      <td>166.50</td>\n",
       "      <td>2778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9468</td>\n",
       "      <td>92.0600</td>\n",
       "      <td>96.50</td>\n",
       "      <td>9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1070</td>\n",
       "      <td>45.2600</td>\n",
       "      <td>47.00</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9046</td>\n",
       "      <td>204.7800</td>\n",
       "      <td>215.50</td>\n",
       "      <td>9046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>168</td>\n",
       "      <td>60.9650</td>\n",
       "      <td>68.50</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>583</td>\n",
       "      <td>263.0500</td>\n",
       "      <td>278.75</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1080</td>\n",
       "      <td>143.0700</td>\n",
       "      <td>153.25</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>142</td>\n",
       "      <td>182.2200</td>\n",
       "      <td>189.75</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7558</td>\n",
       "      <td>394.0200</td>\n",
       "      <td>412.50</td>\n",
       "      <td>7558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1222</td>\n",
       "      <td>345.6700</td>\n",
       "      <td>350.00</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9081</td>\n",
       "      <td>67.2100</td>\n",
       "      <td>72.00</td>\n",
       "      <td>9081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>417</td>\n",
       "      <td>182.4400</td>\n",
       "      <td>189.75</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1087</td>\n",
       "      <td>187.5300</td>\n",
       "      <td>197.50</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9289</td>\n",
       "      <td>388.8000</td>\n",
       "      <td>408.25</td>\n",
       "      <td>9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8120</td>\n",
       "      <td>116.2100</td>\n",
       "      <td>125.75</td>\n",
       "      <td>8120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  purchase_price  selling_price  PRODUCT_ID\n",
       "0          415        270.5600         281.75         415\n",
       "1         3495         20.0100          21.75        3495\n",
       "2          152        205.0800         212.25         152\n",
       "3           72        508.7900         540.75          72\n",
       "4          974        134.0100         144.25         974\n",
       "5         2438         40.8900          43.00        2438\n",
       "6         3900        501.9900         557.75        3900\n",
       "7          361        168.8775         189.75         361\n",
       "8         3575        268.0800         282.25        3575\n",
       "9         6952        144.8300         155.50        6952\n",
       "10        1765        157.1900         163.00        1765\n",
       "11        2778        156.3600         166.50        2778\n",
       "12        9468         92.0600          96.50        9468\n",
       "13        1070         45.2600          47.00        1070\n",
       "14        9046        204.7800         215.50        9046\n",
       "15         168         60.9650          68.50         168\n",
       "16         583        263.0500         278.75         583\n",
       "17        1080        143.0700         153.25        1080\n",
       "18         142        182.2200         189.75         142\n",
       "19        7558        394.0200         412.50        7558\n",
       "20        1222        345.6700         350.00        1222\n",
       "21        9081         67.2100          72.00        9081\n",
       "22         417        182.4400         189.75         417\n",
       "23        1087        187.5300         197.50        1087\n",
       "24        9289        388.8000         408.25        9289\n",
       "25        8120        116.2100         125.75        8120"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detecting the other outliers in the purchasing price \n",
    "\n",
    "# Define the threshold as the highest selling_price\n",
    "threshold = cost_of_goods['selling_price'].max()\n",
    "\n",
    "# Identify rows with purchase_price greater than the threshold\n",
    "large_value_rows = cost_of_goods['purchase_price'] > threshold\n",
    "\n",
    "# Calculate the replacement value: selling_price - 11% * selling_price\n",
    "replacement_value = cost_of_goods['selling_price'] - 0.11 * cost_of_goods['selling_price']\n",
    "\n",
    "# Replace purchase_price values greater than the threshold with the calculated replacement value\n",
    "cost_of_goods.loc[large_value_rows, 'purchase_price'] = replacement_value[large_value_rows]\n",
    "\n",
    "cost_of_goods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e511ccb1",
   "metadata": {},
   "source": [
    "## Q1 → calculate total sales (delivered orders only) per day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e41cf",
   "metadata": {},
   "source": [
    "- to answer this we need to filter out the cancelled orders \n",
    "- then calculate total sales per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc19a688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE        DAY_NAME\n",
       "2023-10-01  Sun         371598.75\n",
       "2023-10-02  Mon         320557.93\n",
       "2023-10-03  Tue         449848.73\n",
       "2023-10-04  Wed         437969.17\n",
       "2023-10-05  Thu         225666.14\n",
       "2023-10-06  Fri         231573.77\n",
       "2023-10-07  Sat         342714.68\n",
       "2023-10-08  Sun         393627.03\n",
       "2023-10-09  Mon         313617.20\n",
       "2023-10-10  Tue         275830.06\n",
       "2023-10-11  Wed         324794.78\n",
       "2023-10-12  Thu         234056.88\n",
       "2023-10-13  Fri         173854.80\n",
       "2023-10-14  Sat         277795.64\n",
       "2023-10-15  Sun         264212.10\n",
       "2023-10-16  Mon         290943.01\n",
       "2023-10-17  Tue         232227.59\n",
       "2023-10-18  Wed         298317.21\n",
       "2023-10-19  Thu         254330.92\n",
       "2023-10-20  Fri         203526.50\n",
       "2023-10-21  Sat         281832.08\n",
       "Name: SALES, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out canceled orders\n",
    "delivered_orders = sales_orders[sales_orders['Order_status'] != 'Canceled']\n",
    "\n",
    "# Group by both 'DATE' and 'DAY_NAME', then calculate total sales for delivered orders\n",
    "total_sales_per_day = delivered_orders.groupby([delivered_orders['DATE'].dt.date, 'DAY_NAME'])['SALES'].sum().round(2)\n",
    "\n",
    "total_sales_per_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ed4f2",
   "metadata": {},
   "source": [
    "## Q2 → Given the 3 weeks of data from sales orders predict the 4th-week (from 22nd to 28th of October) total sales (delivered only)\n",
    "\n",
    "- Feature Engineering: Extract relevant features like week numbers.\n",
    "- Weekly Sales Calculation: Calculate total weekly sales for the given data.\n",
    "- Prediction Model: Use these calculations to predict the 4th-week sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2ce5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted total sales for the 4th week: 2539431.08\n"
     ]
    }
   ],
   "source": [
    "# Extract week number from 'DATE'\n",
    "sales_orders['WEEK_NUMBER'] = sales_orders['DATE'].dt.isocalendar().week\n",
    "\n",
    "# Calculate total sales for each week\n",
    "weekly_sales = sales_orders.groupby('WEEK_NUMBER')['SALES'].sum().reset_index()\n",
    "\n",
    "# Assuming the data contains only the first 3 weeks and you want to predict the 4th week\n",
    "X = weekly_sales['WEEK_NUMBER'].values.reshape(-1, 1)  # Week numbers as features\n",
    "y = weekly_sales['SALES'].values  # Sales as target\n",
    "\n",
    "# Train a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Predict the 4th week (assuming weeks are consecutive and the first week number is correct)\n",
    "# predicted_sales_4th_week = model.predict([[X[-1] + 1]])\n",
    "# Correcting the prediction line to ensure X is a 2D array\n",
    "predicted_sales_4th_week = model.predict([[X[-1][0] + 1]])\n",
    "\n",
    "print(f\"Predicted total sales for the 4th week: {predicted_sales_4th_week[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126df065",
   "metadata": {},
   "source": [
    "## Q3 → Based on your prediction in the previous question, what will be the contribution of Wednesday and Friday in the 4th week (from 22nd to 28th of October).\n",
    "\n",
    "- To estimate the contribution of Wednesday and Friday in the 4th week based on the previous prediction, we need to follow these steps:\n",
    "\n",
    "- Calculate the Proportion of Sales for Wednesday and Friday: Analyze the historical data to find the proportion of sales that occurred on Wednesday and Friday compared to the total weekly sales.\n",
    "- Apply Proportions to the 4th Week's Prediction: Use the calculated proportions to estimate the sales for Wednesday and Friday in the 4th week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "520cefba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Wednesday sales for the 4th week: 13.53\n",
      "Predicted Friday sales for the 4th week: 13.53\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for the predicted total sales for the 4th week\n",
    "predicted_sales_4th_week = 100  # Example value\n",
    "\n",
    "# Calculate the proportion of sales for Wednesday and Friday\n",
    "# First, filter the data for only Wednesday and Friday\n",
    "wed_fri_sales = sales_orders[sales_orders['DAY_NAME'].isin(['Wed', 'Fri'])]\n",
    "\n",
    "# Calculate total sales for Wednesday and Friday\n",
    "total_wed_fri_sales = wed_fri_sales['SALES'].sum()\n",
    "\n",
    "# Calculate total sales for all days in the dataset\n",
    "total_sales = sales_orders['SALES'].sum()\n",
    "\n",
    "# Calculate the proportion of Wednesday and Friday sales to total sales\n",
    "proportion_wed_fri = total_wed_fri_sales / total_sales\n",
    "\n",
    "# Apply the proportion to the 4th week's prediction\n",
    "predicted_wed_fri_sales_4th_week = predicted_sales_4th_week * proportion_wed_fri\n",
    "\n",
    "# Assuming equal distribution between Wednesday and Friday\n",
    "predicted_wed_sales = predicted_wed_fri_sales_4th_week / 2\n",
    "predicted_fri_sales = predicted_wed_fri_sales_4th_week / 2\n",
    "\n",
    "print(f\"Predicted Wednesday sales for the 4th week: {predicted_wed_sales:.2f}\")\n",
    "print(f\"Predicted Friday sales for the 4th week: {predicted_fri_sales:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ffb9d0",
   "metadata": {},
   "source": [
    "## Q4 → Based on the 4 weeks of data, Which week has the highest sales and which day is usually the highest per week in terms of sales (delivered only)\n",
    "\n",
    "- To determine which week has the highest sales and which day is usually the highest per week in terms of sales (considering only delivered orders), follow these steps:\n",
    "\n",
    "- Filter Delivered Orders: Since we're only interested in delivered orders, filter the dataset accordingly.\n",
    "- Calculate Weekly Sales: Sum up sales for each week to find the week with the highest sales.\n",
    "- Identify Highest Sales Day Per Week: For each week, find the day with the highest sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7adf36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week with the highest sales: \n",
      " Week 40, with Total Sales: 2626643.1246\n",
      "Highest sales day per week: \n",
      "\n",
      "    WEEK_NUMBER DAY_NAME        SALES\n",
      "0            39      Sun  404328.5020\n",
      "7            40      Wed  494512.5500\n",
      "9            41      Mon  357130.9463\n",
      "20           42      Wed  337260.7745\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'sales_orders' DataFrame is already filtered for delivered orders\n",
    "\n",
    "# Calculate total sales for each week\n",
    "weekly_sales_totals = sales_orders.groupby('WEEK_NUMBER')['SALES'].sum()\n",
    "\n",
    "# Find the week with the highest sales\n",
    "highest_sales_week = weekly_sales_totals.idxmax()\n",
    "highest_sales_amount = weekly_sales_totals.max()\n",
    "\n",
    "print(f\"Week with the highest sales: \\n Week {highest_sales_week}, with Total Sales: {highest_sales_amount}\")\n",
    "\n",
    "# Calculate the day with the highest sales per week\n",
    "highest_sales_day_per_week = sales_orders.groupby(['WEEK_NUMBER', 'DAY_NAME'])['SALES'].sum().reset_index()\n",
    "\n",
    "# Sort to find the day with the highest sales per week\n",
    "highest_sales_day_per_week = highest_sales_day_per_week.sort_values(by=['WEEK_NUMBER', 'SALES'], ascending=[True, False])\n",
    "\n",
    "# Drop duplicates to keep only the top day per week\n",
    "highest_sales_day_per_week = highest_sales_day_per_week.drop_duplicates(subset=['WEEK_NUMBER'], keep='first')\n",
    "\n",
    "print(\"Highest sales day per week: \\n\")\n",
    "print(highest_sales_day_per_week[['WEEK_NUMBER', 'DAY_NAME', 'SALES']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eda5f8",
   "metadata": {},
   "source": [
    "## Given Dataset2 (Cost_of_Goods) and Dataset3 (Product_sales_order)\n",
    "## Q5 → Calculate the margin percentage per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5972cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PRODUCT_ID  Margin Percentage\n",
      "0             415           3.971606\n",
      "1             415           3.971606\n",
      "2             415           3.971606\n",
      "3             415           3.971606\n",
      "4             415           3.971606\n",
      "...           ...                ...\n",
      "20273        8120           7.586481\n",
      "20274        8120           7.586481\n",
      "20275        8120           7.586481\n",
      "20276        8120           7.586481\n",
      "20277        8120           7.586481\n",
      "\n",
      "[20278 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#to calculate margin % Per product, we've to merge the two dfs into one combined df on the \n",
    "#on the common key which is (PRODUCT_ID).\n",
    "# Join the dataframes based on PRODUCT_ID\n",
    "cost_of_goods['PRODUCT_ID'] = cost_of_goods['product_id'].astype(int)\n",
    "\n",
    "combined_df = pd.merge(cost_of_goods, product_sales_orders, on='PRODUCT_ID', how='inner')\n",
    "\n",
    "# Calculate the margin percentage\n",
    "combined_df['Margin Percentage'] = ((combined_df['selling_price'] - combined_df['purchase_price']) / combined_df['selling_price']) * 100\n",
    "\n",
    "# Display the result\n",
    "print(combined_df[['PRODUCT_ID', 'Margin Percentage']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693565cd",
   "metadata": {},
   "source": [
    "## Q6 → Calculate the gross profit per product.\n",
    "- basically, the Gross Profit = Selling Price - Purchase Price , so we'll use the combined df that we've allready created again and create a new col with this calculation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d526e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PRODUCT_ID  Gross Profit\n",
      "0             415         11.19\n",
      "1             415         11.19\n",
      "2             415         11.19\n",
      "3             415         11.19\n",
      "4             415         11.19\n",
      "...           ...           ...\n",
      "20273        8120          9.54\n",
      "20274        8120          9.54\n",
      "20275        8120          9.54\n",
      "20276        8120          9.54\n",
      "20277        8120          9.54\n",
      "\n",
      "[20278 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gross profit\n",
    "combined_df['Gross Profit'] = combined_df['selling_price'] - combined_df['purchase_price']\n",
    "\n",
    "# Display the result\n",
    "print(combined_df[['PRODUCT_ID', 'Gross Profit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a07c3",
   "metadata": {},
   "source": [
    "## Q7 → What are the top 3 and bottom 3 products in terms of gross profit.\n",
    "\n",
    "- to solve this we'll Sort and Identify Top/Bottom Products:\n",
    "- We’ll sort the products based on their gross profit.\n",
    "- The top 3 products will have the highest gross profit, and the bottom 3 products will have the lowest gross profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2d98acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Products (Highest Gross Profit):\n",
      "      PRODUCT_ID  Gross Profit\n",
      "4518        3900         55.76\n",
      "4421        3900         55.76\n",
      "4423        3900         55.76\n",
      "\n",
      "Bottom 3 Products (Lowest Gross Profit):\n",
      "     PRODUCT_ID  Gross Profit\n",
      "785        3495          1.74\n",
      "784        3495          1.74\n",
      "805        3495          1.74\n"
     ]
    }
   ],
   "source": [
    "# Sort by gross profit (descending order)\n",
    "sorted_df = combined_df.sort_values(by='Gross Profit', ascending=False)\n",
    "\n",
    "# Get the top 3 and bottom 3 products\n",
    "top_3_products = sorted_df.head(3)\n",
    "bottom_3_products = sorted_df.tail(3)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 3 Products (Highest Gross Profit):\")\n",
    "print(top_3_products[['PRODUCT_ID', 'Gross Profit']])\n",
    "\n",
    "print(\"\\nBottom 3 Products (Lowest Gross Profit):\")\n",
    "print(bottom_3_products[['PRODUCT_ID', 'Gross Profit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb59c7e",
   "metadata": {},
   "source": [
    "## Q8 → State your recommendations for how we could further increase our gross profit.\n",
    "- After we Identified which products contribute the most to gross profit. we should Focus on high-margin products (the top 3 highest products )\n",
    "- also regarding the Pricing Strateg, whe should Evaluate our pricing strategy and consider adjusting prices based on market demand and competitor pricing.\n",
    "- Negotiate better terms with suppliers to reduce purchase costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c80ce",
   "metadata": {},
   "source": [
    "## Q9 → If the 3 datasets (Sales_orders, Cost_of_Goods & Product_sales_order) were tables in database, write a simple SQL query to:\n",
    "- create 1 table that has the total number of unique delivered products\n",
    "- and the total number of unique canceled products per day for the first week \n",
    "- and create a flag that is equal to 1 if that day had more than than 5 unique products delivered and 0 else wise.\n",
    "- Also make sure your answer doesn't contain fully duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f045986",
   "metadata": {},
   "source": [
    "```sql\n",
    "\n",
    "CREATE TABLE ProductSummary AS\n",
    "SELECT\n",
    "    DATE,\n",
    "    COUNT(DISTINCT CASE WHEN Order_status = 'Delivered' THEN PRODUCT_ID END) AS DeliveredProducts,\n",
    "    COUNT(DISTINCT CASE WHEN Order_status = 'Canceled' THEN PRODUCT_ID END) AS CanceledProducts,\n",
    "    CASE WHEN COUNT(DISTINCT CASE WHEN Order_status = 'Delivered' THEN PRODUCT_ID END) > 5\n",
    "    THEN 1 ELSE 0 END AS HighProductCountFlag\n",
    "FROM\n",
    "    Sales_orders\n",
    "    JOIN Product_sales_orders ON Sales_orders.ORDER_ID = Product_sales_orders.SALES_ORDER_ID\n",
    "WHERE\n",
    "    DATE BETWEEN '2024-10-01' AND '2024-10-07'\n",
    "GROUP BY\n",
    "    DATE;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1cc555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
